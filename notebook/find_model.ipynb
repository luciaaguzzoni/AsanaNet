{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de02ac1-3f85-480e-a6c4-c7df6c3374f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Libraries and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e6f5c0-903a-43b2-bd06-85534dddceac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img, to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d79f28-7a9f-432a-86ac-84b1bcec9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 100\n",
    "img_width = 100\n",
    "num_classes = 84\n",
    "base_dir = '../data/dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bef2b7-2bf7-4f7b-b77b-869cb6af5177",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6da926-3e69-4f3e-8751-94757c37571e",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59f738bc-b2b2-44a8-afd0-5350ba0cc2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_without_squeezing(image, target_size):\n",
    "    h, w = image.shape[:2]\n",
    "    aspect_ratio = w / h\n",
    "    if aspect_ratio > 1:\n",
    "        new_w = target_size\n",
    "        new_h = int(target_size / aspect_ratio)\n",
    "    else:\n",
    "        new_h = target_size\n",
    "        new_w = int(target_size * aspect_ratio)\n",
    "    resized_img = cv2.resize(image, (new_w, new_h))\n",
    "    canvas = np.full((target_size, target_size, 3), (255,255,255), dtype=np.uint8)\n",
    "    y_offset = (target_size - new_h) // 2\n",
    "    x_offset = (target_size - new_w) // 2\n",
    "    canvas[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = resized_img\n",
    "    return canvas\n",
    "\n",
    "def get_folders_in_directory(directory_path):\n",
    "    # Get the list of all files and folders in the specified directory\n",
    "    items = os.listdir(directory_path)\n",
    "    # Filter out only the folders from the list\n",
    "    folders = [item for item in items if os.path.isdir(os.path.join(directory_path, item))]\n",
    "    return folders\n",
    "    \n",
    "def load_images_from_folder(folder):\n",
    "    # Function to load and preprocess images from a folder\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            img = resize_without_squeezing(img,img_height)\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "def load_images(dir):\n",
    "    labels_name = get_folders_in_directory(dir) # get the list of folder names\n",
    "    labels_dict1 = {label:i for i,label in enumerate(labels_name)} # assign an int for each folder name = asana\n",
    "    labels_dict2 = {i:label for i,label in enumerate(labels_name)}\n",
    "\n",
    "    # Get all images and corresp labels\n",
    "    all_images=[]\n",
    "    all_labels=[]\n",
    "    for label in labels_name:\n",
    "        new_images = load_images_from_folder(dir+'/'+label)\n",
    "        all_images = all_images + new_images\n",
    "        for i in range(len(new_images)):\n",
    "            all_labels.append(labels_dict1[label])\n",
    "\n",
    "    # Ensure that all_image_paths and all_labels are numpy arrays for easier manipulation\n",
    "    images = np.array(all_images)/255 # normalize images to the range [0-1]\n",
    "    labels = np.array(all_labels)\n",
    "\n",
    "    # Shuffle indices and use the shuffled indices to reorder X and y\n",
    "    indices = np.arange(len(images))\n",
    "    np.random.shuffle(indices)\n",
    "    images_shuffled = images[indices]\n",
    "    labels_shuffled = labels[indices]\n",
    "\n",
    "    return images_shuffled, labels_shuffled, labels_dict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae3273e-78e3-496b-acae-2314bcd9a6a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d83aebf1-7989-4b66-be52-ff3021fb3ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(images, labels):\n",
    "    # Split the dataset into training and temporary sets (combined validation and test)\n",
    "    train_data, temp_data, train_labels, temp_labels = train_test_split(\n",
    "        images, labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Split the temporary set into validation and test sets\n",
    "    val_data, test_data, val_labels, test_labels = train_test_split(\n",
    "        temp_data, temp_labels, test_size=0.5, random_state=42)\n",
    "    \n",
    "    train_labels_one_hot = to_categorical(train_labels, num_classes=num_classes)\n",
    "    val_labels_one_hot = to_categorical(val_labels, num_classes=num_classes)\n",
    "    test_labels_one_hot = to_categorical(test_labels, num_classes=num_classes)\n",
    "\n",
    "    return train_data, train_labels_one_hot, val_data, val_labels_one_hot, test_data, test_labels_one_hot\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ab2fb-6629-49c8-82b9-a6a0a6374358",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47460a3f-85b1-43e7-9d0b-51b9a76c5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ImageDataGenerator class.\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range = 30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "068f2270-4341-43aa-acb3-b290685315e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, optimizer, metrics):\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def save_model(model):\n",
    "    model_file = '../models/param_iteration_dn3.pkl'\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa03ccdc-039a-43b5-b4ed-4026e664257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, train_labels, val_data, val_labels, test_data, test_labels, model_type, optimizer, batch_size, num_epochs, metrics=['accuracy']):\n",
    "\n",
    "    result_dict = {}\n",
    "    result_dict[\"model\"] = model_type\n",
    "    result_dict[\"optimizer\"] = optimizer\n",
    "    result_dict[\"num_epochs\"] = num_epochs\n",
    "    result_dict[\"batch_size\"] = batch_size\n",
    "   \n",
    "    if model_type == 'CNN':\n",
    "        model = create_CNN()\n",
    "    elif model_type == 'DenseNet':\n",
    "        model = create_DN2()\n",
    "        \n",
    "    # optimizer\n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=10000, decay_rate=0.9, staircase=True)\n",
    "    if optimizer=='adam':\n",
    "        opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    elif optimizer=='rmsprop':\n",
    "        opt = keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "    elif optimizer=='sgd':\n",
    "        opt = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "    # compile model\n",
    "    model = compile_model(model, opt, metrics)\n",
    "\n",
    "    # train model\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.001, verbose=1, patience = 5, restore_best_weights=True)\n",
    "\n",
    "    train_datagen = datagen.flow(train_data, train_labels, batch_size=batch_size)\n",
    "    val_datagen = datagen.flow(val_data, val_labels, batch_size=batch_size)\n",
    "    history = model.fit(train_datagen, epochs=num_epochs, callbacks=[early_stopping], validation_data=val_datagen)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "    print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "    result_dict[\"actual_num_epochs\"] = len(history.history['loss'])\n",
    "    result_dict[\"accuracy\"] = test_acc\n",
    "    return result_dict, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfbe83e8-2e5f-4646-9e89-b1ea3cbb88bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(param_grid, train_data, train_labels, val_data, val_labels, test_data, test_labels):\n",
    "    results = []\n",
    "    i=0\n",
    "    best_accuracy = (-1,0)\n",
    "\n",
    "    for model_type in param_grid['model']:\n",
    "        for n_ep in param_grid['epochs']:\n",
    "            for b_size in param_grid[\"batch_size\"]:\n",
    "                for opt in param_grid['optimizer']:\n",
    "                    print(f\"number of epochs: {n_ep}, batch size: {b_size}, optimizer: {opt}\")\n",
    "                    d, model = train_model(train_data, train_labels, val_data, val_labels, test_data, test_labels, \n",
    "                                    model_type, opt, b_size, n_ep, metrics=['accuracy'])\n",
    "                    results.append(d)\n",
    "                    if d[\"accuracy\"] > best_accuracy[1]:\n",
    "                        best_accuracy = (i,d[\"accuracy\"])\n",
    "                        save_model(model)\n",
    "                    i+=1  \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07436eb-13c3-4ac7-b839-8cee1df042b3",
   "metadata": {},
   "source": [
    "##### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ebe0d9-68fb-4ab3-b994-fab884b1221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN():\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(16, (3, 3), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.2), #to avoid overfitting\n",
    "        \n",
    "        layers.Conv2D(32, (3, 3), padding='same',  activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        #layers.Dense(512, activation='relu'), #prova anche 256 e 1024\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax') \n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ab0831-aff9-4c36-898d-7b973c672960",
   "metadata": {},
   "source": [
    "##### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84381ddc-5935-4f58-aa98-ea204cd5eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DN():\n",
    "    ptrain_model = tf.keras.applications.DenseNet121(input_shape=(img_height,img_width,3),\n",
    "                                                      include_top=False,\n",
    "                                                      weights='imagenet',\n",
    "                                                      pooling='avg')\n",
    "    ptrain_model.trainable = False\n",
    "    \n",
    "    inputs = ptrain_model.input\n",
    "\n",
    "    # Trying different configurations, such as [512, 256], [256, 128], etc., could be beneficial.\n",
    "    drop_layer = tf.keras.layers.Dropout(0.25)(ptrain_model.output)\n",
    "    x_layer = tf.keras.layers.Dense(512, activation='relu')(drop_layer)\n",
    "    x_layer1 = tf.keras.layers.Dense(128, activation='relu')(x_layer)\n",
    "    drop_layer1 = tf.keras.layers.Dropout(0.20)(x_layer1)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(drop_layer1)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "                  \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f2b560-412a-4e70-85ae-4bdcf749175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DN2():\n",
    "    # adding BatchNormalization\n",
    "    ptrain_model = tf.keras.applications.DenseNet121(input_shape=(img_height,img_width,3),\n",
    "                                                      include_top=False,\n",
    "                                                      weights='imagenet',\n",
    "                                                      pooling='avg')\n",
    "    ptrain_model.trainable = False\n",
    "    \n",
    "    inputs = ptrain_model.input\n",
    "\n",
    "    # Trying different configurations, such as [512, 256], [256, 128], etc., could be beneficial.\n",
    "    drop_layer = tf.keras.layers.Dropout(0.25)(ptrain_model.output)\n",
    "    x_layer = tf.keras.layers.Dense(512, activation='relu')(drop_layer)\n",
    "    x_layer = tf.keras.layers.BatchNormalization()(x_layer)\n",
    "    \n",
    "    x_layer1 = tf.keras.layers.Dense(256, activation='relu')(x_layer)\n",
    "    x_layer1 = tf.keras.layers.BatchNormalization()(x_layer1)\n",
    "    \n",
    "    drop_layer1 = tf.keras.layers.Dropout(0.20)(x_layer1)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(drop_layer1)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "                  \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eea5af3-7a32-41b3-9f67-47e45d9b2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DN3():\n",
    "    # adding BatchNormalization\n",
    "    ptrain_model = tf.keras.applications.DenseNet121(input_shape=(img_height,img_width,3),\n",
    "                                                      include_top=False,\n",
    "                                                      weights='imagenet',\n",
    "                                                      pooling='avg')\n",
    "    ptrain_model.trainable = False\n",
    "    \n",
    "    inputs = ptrain_model.input\n",
    "\n",
    "    # Trying different configurations, such as [512, 256], [256, 128], etc., could be beneficial.\n",
    "    drop_layer = tf.keras.layers.Dropout(0.25)(ptrain_model.output)\n",
    "    x_layer = tf.keras.layers.Dense(512, activation='relu')(drop_layer)\n",
    "    x_layer = tf.keras.layers.BatchNormalization()(x_layer)\n",
    "    \n",
    "    x_layer1 = tf.keras.layers.Dense(256, activation='relu')(x_layer)\n",
    "    x_layer1 = tf.keras.layers.BatchNormalization()(x_layer1)\n",
    "\n",
    "    x_layer2 = tf.keras.layers.Dense(128, activation='relu')(x_layer1)\n",
    "    x_layer2 = tf.keras.layers.BatchNormalization()(x_layer2)\n",
    "    \n",
    "    drop_layer1 = tf.keras.layers.Dropout(0.20)(x_layer2)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(drop_layer1)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "                  \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c8d2b-1311-4e00-948b-7bd22c50d9ac",
   "metadata": {},
   "source": [
    "#### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac5232-e14e-409f-ab3f-4dbd41a61ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_results(new_results_list):\n",
    "    try:\n",
    "        training_df = pd.read_csv('../data/training_table.cvs')\n",
    "        result_df = pd.DataFrame(new_results_list)\n",
    "        new_training_df = pd.concat([training_df, new_results_list]).reset_index(drop=True)\n",
    "        new_training_df.to_csv(\"../data/training_table.cvs\", index=False)\n",
    "    except:\n",
    "        result_df = pd.DataFrame(new_results_list)\n",
    "        result_df.to_csv(\"../data/training_table.cvs\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3002ed-9b20-4e2c-8d6d-de38afd65f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68966ac6-21bf-4d39-9dee-c675fab732e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b3a2c8b-6e44-4555-8a12-2dd0d1aebaac",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ccdd01-1291-4592-a4c5-8a42ca32e1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e17a2-66be-406d-ae95-2957fd9f93a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd2d23f-1892-4a69-890c-7618f256e375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "262997e9-964b-448c-83ac-abb872da8019",
   "metadata": {},
   "source": [
    "## 'main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf2855fc-d079-425c-b81a-e69683d4ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "images, labels, labels_dict = load_images(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0971e4b9-626c-43a3-a67e-d6a6d7cb30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = split(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f4b9c1-4796-4f6b-9c95-67b55ac69100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epochs: 30, batch size: 8, optimizer: adam\n",
      "Epoch 1/30\n",
      "337/337 [==============================] - 46s 115ms/step - loss: 4.2737 - accuracy: 0.0675 - val_loss: 3.5490 - val_accuracy: 0.1334\n",
      "Epoch 2/30\n",
      "337/337 [==============================] - 35s 103ms/step - loss: 3.4251 - accuracy: 0.1540 - val_loss: 3.0234 - val_accuracy: 0.2357\n",
      "Epoch 3/30\n",
      "337/337 [==============================] - 35s 104ms/step - loss: 3.1012 - accuracy: 0.2037 - val_loss: 2.7901 - val_accuracy: 0.2496\n",
      "Epoch 4/30\n",
      "337/337 [==============================] - 34s 102ms/step - loss: 2.9228 - accuracy: 0.2412 - val_loss: 2.5823 - val_accuracy: 0.2894\n",
      "Epoch 5/30\n",
      "337/337 [==============================] - 35s 104ms/step - loss: 2.7676 - accuracy: 0.2709 - val_loss: 2.4836 - val_accuracy: 0.3241\n",
      "Epoch 6/30\n",
      "337/337 [==============================] - 34s 100ms/step - loss: 2.6859 - accuracy: 0.2757 - val_loss: 2.4663 - val_accuracy: 0.3310\n",
      "Epoch 7/30\n",
      "337/337 [==============================] - 33s 99ms/step - loss: 2.6120 - accuracy: 0.3050 - val_loss: 2.4536 - val_accuracy: 0.3085\n",
      "Epoch 8/30\n",
      "337/337 [==============================] - 51s 152ms/step - loss: 2.5592 - accuracy: 0.3132 - val_loss: 2.4084 - val_accuracy: 0.3362\n",
      "Epoch 9/30\n",
      "337/337 [==============================] - 37s 110ms/step - loss: 2.5103 - accuracy: 0.3317 - val_loss: 2.3763 - val_accuracy: 0.3692\n",
      "Epoch 10/30\n",
      "337/337 [==============================] - 35s 103ms/step - loss: 2.4544 - accuracy: 0.3232 - val_loss: 2.4072 - val_accuracy: 0.3414\n",
      "Epoch 11/30\n",
      "337/337 [==============================] - 36s 108ms/step - loss: 2.4271 - accuracy: 0.3358 - val_loss: 2.3171 - val_accuracy: 0.3726\n",
      "Epoch 12/30\n",
      "337/337 [==============================] - 38s 112ms/step - loss: 2.4003 - accuracy: 0.3425 - val_loss: 2.3984 - val_accuracy: 0.3397\n",
      "Epoch 13/30\n",
      "337/337 [==============================] - 36s 106ms/step - loss: 2.3506 - accuracy: 0.3584 - val_loss: 2.3240 - val_accuracy: 0.3795\n",
      "Epoch 14/30\n",
      "337/337 [==============================] - 36s 107ms/step - loss: 2.3511 - accuracy: 0.3570 - val_loss: 2.3089 - val_accuracy: 0.3553\n",
      "Epoch 15/30\n",
      "337/337 [==============================] - 38s 112ms/step - loss: 2.2820 - accuracy: 0.3766 - val_loss: 2.3029 - val_accuracy: 0.3432\n",
      "Epoch 16/30\n",
      "337/337 [==============================] - 38s 112ms/step - loss: 2.2639 - accuracy: 0.3699 - val_loss: 2.2812 - val_accuracy: 0.3570\n",
      "Epoch 17/30\n",
      "337/337 [==============================] - 37s 109ms/step - loss: 2.2338 - accuracy: 0.3792 - val_loss: 2.1851 - val_accuracy: 0.3830\n",
      "Epoch 18/30\n",
      "337/337 [==============================] - 35s 104ms/step - loss: 2.2158 - accuracy: 0.3874 - val_loss: 2.2931 - val_accuracy: 0.3934\n",
      "Epoch 19/30\n",
      "337/337 [==============================] - 35s 105ms/step - loss: 2.1878 - accuracy: 0.3892 - val_loss: 2.2764 - val_accuracy: 0.3813\n",
      "Epoch 20/30\n",
      "337/337 [==============================] - 39s 115ms/step - loss: 2.1743 - accuracy: 0.4022 - val_loss: 2.2595 - val_accuracy: 0.3951\n",
      "Epoch 21/30\n",
      "337/337 [==============================] - 36s 107ms/step - loss: 2.2087 - accuracy: 0.3878 - val_loss: 2.1464 - val_accuracy: 0.4194\n",
      "Epoch 22/30\n",
      "337/337 [==============================] - 36s 106ms/step - loss: 2.1790 - accuracy: 0.3959 - val_loss: 2.2390 - val_accuracy: 0.3847\n",
      "Epoch 23/30\n",
      "337/337 [==============================] - 36s 108ms/step - loss: 2.1623 - accuracy: 0.3989 - val_loss: 2.1937 - val_accuracy: 0.3969\n",
      "Epoch 24/30\n",
      "337/337 [==============================] - 36s 108ms/step - loss: 2.1572 - accuracy: 0.3915 - val_loss: 2.3037 - val_accuracy: 0.3622\n",
      "Epoch 25/30\n",
      "337/337 [==============================] - 36s 107ms/step - loss: 2.1332 - accuracy: 0.4193 - val_loss: 2.2544 - val_accuracy: 0.3830\n",
      "Epoch 26/30\n",
      "337/337 [==============================] - ETA: 0s - loss: 2.1432 - accuracy: 0.4145Restoring model weights from the end of the best epoch: 21.\n",
      "337/337 [==============================] - 36s 108ms/step - loss: 2.1432 - accuracy: 0.4145 - val_loss: 2.1573 - val_accuracy: 0.4142\n",
      "Epoch 26: early stopping\n",
      "19/19 [==============================] - 4s 217ms/step - loss: 1.9068 - accuracy: 0.4723\n",
      "Test accuracy: 0.4723183512687683\n",
      "number of epochs: 30, batch size: 8, optimizer: rmsprop\n",
      "Epoch 1/30\n",
      "337/337 [==============================] - 46s 115ms/step - loss: 4.2792 - accuracy: 0.0649 - val_loss: 3.6493 - val_accuracy: 0.1386\n",
      "Epoch 2/30\n",
      "337/337 [==============================] - 41s 121ms/step - loss: 3.5929 - accuracy: 0.1358 - val_loss: 3.1767 - val_accuracy: 0.1924\n",
      "Epoch 3/30\n",
      "337/337 [==============================] - 37s 110ms/step - loss: 3.3007 - accuracy: 0.1800 - val_loss: 2.9420 - val_accuracy: 0.2617\n",
      "Epoch 4/30\n",
      "337/337 [==============================] - 38s 113ms/step - loss: 3.1929 - accuracy: 0.2137 - val_loss: 3.0379 - val_accuracy: 0.2461\n",
      "Epoch 5/30\n",
      "337/337 [==============================] - 35s 105ms/step - loss: 3.1008 - accuracy: 0.2360 - val_loss: 2.8154 - val_accuracy: 0.3120\n",
      "Epoch 6/30\n",
      "337/337 [==============================] - 36s 106ms/step - loss: 3.0130 - accuracy: 0.2494 - val_loss: 2.9336 - val_accuracy: 0.2721\n",
      "Epoch 7/30\n",
      "337/337 [==============================] - 35s 105ms/step - loss: 2.9649 - accuracy: 0.2768 - val_loss: 2.7740 - val_accuracy: 0.2894\n",
      "Epoch 8/30\n",
      "337/337 [==============================] - 36s 108ms/step - loss: 2.9356 - accuracy: 0.2668 - val_loss: 2.7032 - val_accuracy: 0.3206\n",
      "Epoch 9/30\n",
      "337/337 [==============================] - 36s 108ms/step - loss: 2.8613 - accuracy: 0.2998 - val_loss: 2.6229 - val_accuracy: 0.3622\n",
      "Epoch 10/30\n",
      "337/337 [==============================] - 36s 106ms/step - loss: 2.8274 - accuracy: 0.3091 - val_loss: 2.7026 - val_accuracy: 0.3189\n",
      "Epoch 11/30\n",
      "337/337 [==============================] - 35s 105ms/step - loss: 2.7690 - accuracy: 0.3139 - val_loss: 2.6343 - val_accuracy: 0.3518\n",
      "Epoch 12/30\n",
      "337/337 [==============================] - 36s 106ms/step - loss: 2.7976 - accuracy: 0.3113 - val_loss: 2.6511 - val_accuracy: 0.3484\n",
      "Epoch 13/30\n",
      "337/337 [==============================] - 38s 111ms/step - loss: 2.8123 - accuracy: 0.3076 - val_loss: 2.6349 - val_accuracy: 0.3189\n",
      "Epoch 14/30\n",
      "337/337 [==============================] - ETA: 0s - loss: 2.7866 - accuracy: 0.3184Restoring model weights from the end of the best epoch: 9.\n",
      "337/337 [==============================] - 38s 111ms/step - loss: 2.7866 - accuracy: 0.3184 - val_loss: 2.5997 - val_accuracy: 0.3449\n",
      "Epoch 14: early stopping\n",
      "19/19 [==============================] - 4s 232ms/step - loss: 2.4169 - accuracy: 0.3720\n",
      "Test accuracy: 0.37197232246398926\n",
      "number of epochs: 30, batch size: 8, optimizer: sgd\n",
      "Epoch 1/30\n",
      "337/337 [==============================] - 46s 116ms/step - loss: 5.1945 - accuracy: 0.0189 - val_loss: 4.5897 - val_accuracy: 0.0295\n",
      "Epoch 2/30\n",
      "337/337 [==============================] - 37s 111ms/step - loss: 4.9154 - accuracy: 0.0245 - val_loss: 4.4573 - val_accuracy: 0.0451\n",
      "Epoch 3/30\n",
      "337/337 [==============================] - 36s 107ms/step - loss: 4.6477 - accuracy: 0.0390 - val_loss: 4.2039 - val_accuracy: 0.0745\n",
      "Epoch 4/30\n",
      "337/337 [==============================] - 37s 109ms/step - loss: 4.4382 - accuracy: 0.0516 - val_loss: 3.9499 - val_accuracy: 0.0971\n",
      "Epoch 5/30\n",
      "337/337 [==============================] - 35s 105ms/step - loss: 4.2359 - accuracy: 0.0720 - val_loss: 3.8868 - val_accuracy: 0.0953\n",
      "Epoch 6/30\n",
      "337/337 [==============================] - 36s 108ms/step - loss: 4.1442 - accuracy: 0.0709 - val_loss: 3.7030 - val_accuracy: 0.1196\n",
      "Epoch 7/30\n",
      "337/337 [==============================] - 35s 105ms/step - loss: 4.0153 - accuracy: 0.0905 - val_loss: 3.6100 - val_accuracy: 0.1231\n",
      "Epoch 8/30\n",
      "337/337 [==============================] - 38s 113ms/step - loss: 3.9552 - accuracy: 0.0879 - val_loss: 3.5179 - val_accuracy: 0.1473\n",
      "Epoch 9/30\n",
      "337/337 [==============================] - 36s 106ms/step - loss: 3.8311 - accuracy: 0.1043 - val_loss: 3.4995 - val_accuracy: 0.1282\n",
      "Epoch 10/30\n",
      "337/337 [==============================] - 44s 130ms/step - loss: 3.7147 - accuracy: 0.1236 - val_loss: 3.3202 - val_accuracy: 0.1854\n",
      "Epoch 11/30\n",
      "337/337 [==============================] - 41s 122ms/step - loss: 3.6614 - accuracy: 0.1247 - val_loss: 3.3079 - val_accuracy: 0.1872\n",
      "Epoch 12/30\n",
      "337/337 [==============================] - 37s 109ms/step - loss: 3.5922 - accuracy: 0.1432 - val_loss: 3.2514 - val_accuracy: 0.1889\n",
      "Epoch 13/30\n",
      "337/337 [==============================] - 36s 106ms/step - loss: 3.5276 - accuracy: 0.1488 - val_loss: 3.2055 - val_accuracy: 0.1802\n",
      "Epoch 14/30\n",
      "337/337 [==============================] - 35s 104ms/step - loss: 3.4922 - accuracy: 0.1477 - val_loss: 3.1525 - val_accuracy: 0.2062\n",
      "Epoch 15/30\n",
      "337/337 [==============================] - 36s 107ms/step - loss: 3.3974 - accuracy: 0.1581 - val_loss: 3.1023 - val_accuracy: 0.2236\n",
      "Epoch 16/30\n",
      "337/337 [==============================] - 37s 109ms/step - loss: 3.4142 - accuracy: 0.1677 - val_loss: 3.0199 - val_accuracy: 0.2288\n",
      "Epoch 17/30\n",
      "337/337 [==============================] - 37s 109ms/step - loss: 3.3099 - accuracy: 0.1822 - val_loss: 2.9754 - val_accuracy: 0.2461\n",
      "Epoch 18/30\n",
      "337/337 [==============================] - 37s 110ms/step - loss: 3.2794 - accuracy: 0.1896 - val_loss: 2.9372 - val_accuracy: 0.2392\n",
      "Epoch 19/30\n",
      "337/337 [==============================] - 35s 105ms/step - loss: 3.2350 - accuracy: 0.1892 - val_loss: 2.9653 - val_accuracy: 0.2461\n",
      "Epoch 20/30\n",
      "337/337 [==============================] - 36s 106ms/step - loss: 3.2026 - accuracy: 0.1952 - val_loss: 2.8514 - val_accuracy: 0.2704\n",
      "Epoch 21/30\n",
      "337/337 [==============================] - 35s 105ms/step - loss: 3.1757 - accuracy: 0.2063 - val_loss: 2.8488 - val_accuracy: 0.2790\n",
      "Epoch 22/30\n",
      "337/337 [==============================] - 36s 108ms/step - loss: 3.0904 - accuracy: 0.2189 - val_loss: 2.8603 - val_accuracy: 0.2548\n",
      "Epoch 23/30\n",
      "337/337 [==============================] - 36s 108ms/step - loss: 3.0761 - accuracy: 0.2182 - val_loss: 2.7786 - val_accuracy: 0.3033\n",
      "Epoch 24/30\n",
      "337/337 [==============================] - 37s 110ms/step - loss: 3.0336 - accuracy: 0.2315 - val_loss: 2.8754 - val_accuracy: 0.2738\n",
      "Epoch 25/30\n",
      "337/337 [==============================] - 36s 107ms/step - loss: 3.0223 - accuracy: 0.2271 - val_loss: 2.8125 - val_accuracy: 0.2444\n",
      "Epoch 26/30\n",
      "337/337 [==============================] - 37s 109ms/step - loss: 2.9769 - accuracy: 0.2356 - val_loss: 2.7851 - val_accuracy: 0.2565\n",
      "Epoch 27/30\n",
      "337/337 [==============================] - 37s 109ms/step - loss: 2.9939 - accuracy: 0.2364 - val_loss: 2.7621 - val_accuracy: 0.2790\n",
      "Epoch 28/30\n",
      "337/337 [==============================] - ETA: 0s - loss: 2.9522 - accuracy: 0.2364Restoring model weights from the end of the best epoch: 23.\n",
      "337/337 [==============================] - 37s 109ms/step - loss: 2.9522 - accuracy: 0.2364 - val_loss: 2.7136 - val_accuracy: 0.2860\n",
      "Epoch 28: early stopping\n",
      "19/19 [==============================] - 8s 432ms/step - loss: 2.5868 - accuracy: 0.3253\n",
      "Test accuracy: 0.3252595067024231\n",
      "number of epochs: 30, batch size: 16, optimizer: adam\n",
      "Epoch 1/30\n",
      "169/169 [==============================] - 48s 215ms/step - loss: 4.2648 - accuracy: 0.0761 - val_loss: 3.4149 - val_accuracy: 0.1646\n",
      "Epoch 2/30\n",
      "169/169 [==============================] - 28s 166ms/step - loss: 3.3205 - accuracy: 0.1677 - val_loss: 2.9025 - val_accuracy: 0.2426\n",
      "Epoch 3/30\n",
      "169/169 [==============================] - 33s 193ms/step - loss: 2.9006 - accuracy: 0.2412 - val_loss: 2.6481 - val_accuracy: 0.2929\n",
      "Epoch 4/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 2.7136 - accuracy: 0.2724 - val_loss: 2.6685 - val_accuracy: 0.2756\n",
      "Epoch 5/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 2.5366 - accuracy: 0.3113 - val_loss: 2.3316 - val_accuracy: 0.3518\n",
      "Epoch 6/30\n",
      "169/169 [==============================] - 28s 164ms/step - loss: 2.4498 - accuracy: 0.3336 - val_loss: 2.4066 - val_accuracy: 0.3310\n",
      "Epoch 7/30\n",
      "169/169 [==============================] - 28s 164ms/step - loss: 2.3708 - accuracy: 0.3570 - val_loss: 2.3892 - val_accuracy: 0.3345\n",
      "Epoch 8/30\n",
      "169/169 [==============================] - 28s 165ms/step - loss: 2.2806 - accuracy: 0.3666 - val_loss: 2.2960 - val_accuracy: 0.3622\n",
      "Epoch 9/30\n",
      "169/169 [==============================] - 28s 165ms/step - loss: 2.2450 - accuracy: 0.3685 - val_loss: 2.3198 - val_accuracy: 0.3622\n",
      "Epoch 10/30\n",
      "169/169 [==============================] - 28s 164ms/step - loss: 2.2245 - accuracy: 0.3840 - val_loss: 2.3177 - val_accuracy: 0.3744\n",
      "Epoch 11/30\n",
      "169/169 [==============================] - 28s 163ms/step - loss: 2.1517 - accuracy: 0.4011 - val_loss: 2.2472 - val_accuracy: 0.3622\n",
      "Epoch 12/30\n",
      "169/169 [==============================] - 29s 169ms/step - loss: 2.1283 - accuracy: 0.4108 - val_loss: 2.1962 - val_accuracy: 0.3917\n",
      "Epoch 13/30\n",
      "169/169 [==============================] - 28s 164ms/step - loss: 2.1214 - accuracy: 0.4022 - val_loss: 2.2286 - val_accuracy: 0.4038\n",
      "Epoch 14/30\n",
      "169/169 [==============================] - 32s 192ms/step - loss: 2.0757 - accuracy: 0.4152 - val_loss: 2.2111 - val_accuracy: 0.3795\n",
      "Epoch 15/30\n",
      "169/169 [==============================] - 28s 164ms/step - loss: 2.0829 - accuracy: 0.4204 - val_loss: 2.1855 - val_accuracy: 0.4073\n",
      "Epoch 16/30\n",
      "169/169 [==============================] - 28s 164ms/step - loss: 1.9748 - accuracy: 0.4382 - val_loss: 2.3334 - val_accuracy: 0.3640\n",
      "Epoch 17/30\n",
      "169/169 [==============================] - 28s 164ms/step - loss: 1.9848 - accuracy: 0.4356 - val_loss: 2.1430 - val_accuracy: 0.3795\n",
      "Epoch 18/30\n",
      "169/169 [==============================] - 28s 164ms/step - loss: 1.9621 - accuracy: 0.4430 - val_loss: 2.1556 - val_accuracy: 0.4159\n",
      "Epoch 19/30\n",
      "169/169 [==============================] - 28s 165ms/step - loss: 1.9946 - accuracy: 0.4371 - val_loss: 2.2065 - val_accuracy: 0.4021\n",
      "Epoch 20/30\n",
      "169/169 [==============================] - 28s 164ms/step - loss: 1.9027 - accuracy: 0.4623 - val_loss: 2.2408 - val_accuracy: 0.4142\n",
      "Epoch 21/30\n",
      "169/169 [==============================] - 28s 166ms/step - loss: 1.8739 - accuracy: 0.4597 - val_loss: 2.1607 - val_accuracy: 0.4055\n",
      "Epoch 22/30\n",
      "169/169 [==============================] - 28s 168ms/step - loss: 1.8997 - accuracy: 0.4508 - val_loss: 2.1956 - val_accuracy: 0.4125\n",
      "Epoch 23/30\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.8916 - accuracy: 0.4657Restoring model weights from the end of the best epoch: 18.\n",
      "169/169 [==============================] - 28s 165ms/step - loss: 1.8916 - accuracy: 0.4657 - val_loss: 2.1810 - val_accuracy: 0.3744\n",
      "Epoch 23: early stopping\n",
      "19/19 [==============================] - 4s 218ms/step - loss: 1.8293 - accuracy: 0.5000\n",
      "Test accuracy: 0.5\n",
      "number of epochs: 30, batch size: 16, optimizer: rmsprop\n",
      "Epoch 1/30\n",
      "169/169 [==============================] - 36s 177ms/step - loss: 4.3111 - accuracy: 0.0668 - val_loss: 3.7135 - val_accuracy: 0.1542\n",
      "Epoch 2/30\n",
      "169/169 [==============================] - 28s 163ms/step - loss: 3.3877 - accuracy: 0.1644 - val_loss: 3.0985 - val_accuracy: 0.2097\n",
      "Epoch 3/30\n",
      "169/169 [==============================] - 28s 163ms/step - loss: 2.9731 - accuracy: 0.2475 - val_loss: 2.7878 - val_accuracy: 0.2929\n",
      "Epoch 4/30\n",
      "169/169 [==============================] - 28s 163ms/step - loss: 2.7901 - accuracy: 0.2831 - val_loss: 2.6858 - val_accuracy: 0.2738\n",
      "Epoch 5/30\n",
      "169/169 [==============================] - 28s 164ms/step - loss: 2.7092 - accuracy: 0.3006 - val_loss: 2.6190 - val_accuracy: 0.2981\n",
      "Epoch 6/30\n",
      "169/169 [==============================] - 28s 163ms/step - loss: 2.6235 - accuracy: 0.3046 - val_loss: 2.5164 - val_accuracy: 0.3189\n",
      "Epoch 7/30\n",
      "169/169 [==============================] - 28s 164ms/step - loss: 2.4633 - accuracy: 0.3455 - val_loss: 2.5462 - val_accuracy: 0.3224\n",
      "Epoch 8/30\n",
      "169/169 [==============================] - 28s 165ms/step - loss: 2.4359 - accuracy: 0.3581 - val_loss: 2.5023 - val_accuracy: 0.3449\n",
      "Epoch 9/30\n",
      "169/169 [==============================] - 28s 164ms/step - loss: 2.3185 - accuracy: 0.3840 - val_loss: 2.4160 - val_accuracy: 0.3501\n",
      "Epoch 10/30\n",
      "169/169 [==============================] - 29s 170ms/step - loss: 2.3536 - accuracy: 0.3788 - val_loss: 2.4429 - val_accuracy: 0.3588\n",
      "Epoch 11/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 2.3142 - accuracy: 0.3885 - val_loss: 2.3025 - val_accuracy: 0.3951\n",
      "Epoch 12/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 2.2523 - accuracy: 0.3989 - val_loss: 2.3345 - val_accuracy: 0.4003\n",
      "Epoch 13/30\n",
      "169/169 [==============================] - 27s 160ms/step - loss: 2.2019 - accuracy: 0.4108 - val_loss: 2.3174 - val_accuracy: 0.3865\n",
      "Epoch 14/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 2.1942 - accuracy: 0.4145 - val_loss: 2.3041 - val_accuracy: 0.4107\n",
      "Epoch 15/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 2.2059 - accuracy: 0.4111 - val_loss: 2.3596 - val_accuracy: 0.3882\n",
      "Epoch 16/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 2.1658 - accuracy: 0.4223 - val_loss: 2.3048 - val_accuracy: 0.3865\n",
      "Epoch 17/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 2.1658 - accuracy: 0.4200 - val_loss: 2.2230 - val_accuracy: 0.4090\n",
      "Epoch 18/30\n",
      "169/169 [==============================] - 27s 160ms/step - loss: 2.1252 - accuracy: 0.4330 - val_loss: 2.3197 - val_accuracy: 0.3899\n",
      "Epoch 19/30\n",
      "169/169 [==============================] - 28s 167ms/step - loss: 2.1533 - accuracy: 0.4282 - val_loss: 2.1703 - val_accuracy: 0.4177\n",
      "Epoch 20/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 2.0588 - accuracy: 0.4263 - val_loss: 2.2413 - val_accuracy: 0.4055\n",
      "Epoch 21/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 2.0965 - accuracy: 0.4427 - val_loss: 2.2706 - val_accuracy: 0.4159\n",
      "Epoch 22/30\n",
      "169/169 [==============================] - 28s 163ms/step - loss: 2.0444 - accuracy: 0.4442 - val_loss: 2.2195 - val_accuracy: 0.4073\n",
      "Epoch 23/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 2.0607 - accuracy: 0.4449 - val_loss: 2.3307 - val_accuracy: 0.3744\n",
      "Epoch 24/30\n",
      "169/169 [==============================] - ETA: 0s - loss: 2.0300 - accuracy: 0.4505Restoring model weights from the end of the best epoch: 19.\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 2.0300 - accuracy: 0.4505 - val_loss: 2.2484 - val_accuracy: 0.3969\n",
      "Epoch 24: early stopping\n",
      "19/19 [==============================] - 4s 203ms/step - loss: 1.8955 - accuracy: 0.4862\n",
      "Test accuracy: 0.48615917563438416\n",
      "number of epochs: 30, batch size: 16, optimizer: sgd\n",
      "Epoch 1/30\n",
      "169/169 [==============================] - 35s 171ms/step - loss: 5.1809 - accuracy: 0.0141 - val_loss: 4.6394 - val_accuracy: 0.0191\n",
      "Epoch 2/30\n",
      "169/169 [==============================] - 28s 167ms/step - loss: 5.0898 - accuracy: 0.0160 - val_loss: 4.5511 - val_accuracy: 0.0260\n",
      "Epoch 3/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 4.9267 - accuracy: 0.0152 - val_loss: 4.4329 - val_accuracy: 0.0243\n",
      "Epoch 4/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 4.7672 - accuracy: 0.0286 - val_loss: 4.3737 - val_accuracy: 0.0312\n",
      "Epoch 5/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 4.6363 - accuracy: 0.0378 - val_loss: 4.2859 - val_accuracy: 0.0555\n",
      "Epoch 6/30\n",
      "169/169 [==============================] - 28s 166ms/step - loss: 4.5206 - accuracy: 0.0434 - val_loss: 4.1293 - val_accuracy: 0.0572\n",
      "Epoch 7/30\n",
      "169/169 [==============================] - 29s 173ms/step - loss: 4.4324 - accuracy: 0.0390 - val_loss: 4.0948 - val_accuracy: 0.0728\n",
      "Epoch 8/30\n",
      "169/169 [==============================] - 29s 173ms/step - loss: 4.3435 - accuracy: 0.0516 - val_loss: 3.9865 - val_accuracy: 0.0867\n",
      "Epoch 9/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 4.2522 - accuracy: 0.0635 - val_loss: 3.9295 - val_accuracy: 0.0676\n",
      "Epoch 10/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 4.1935 - accuracy: 0.0779 - val_loss: 3.8040 - val_accuracy: 0.0988\n",
      "Epoch 11/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 4.0775 - accuracy: 0.0842 - val_loss: 3.7576 - val_accuracy: 0.1213\n",
      "Epoch 12/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 4.0335 - accuracy: 0.0846 - val_loss: 3.7516 - val_accuracy: 0.1144\n",
      "Epoch 13/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 3.9553 - accuracy: 0.0928 - val_loss: 3.6435 - val_accuracy: 0.1369\n",
      "Epoch 14/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 3.8782 - accuracy: 0.1035 - val_loss: 3.6007 - val_accuracy: 0.1109\n",
      "Epoch 15/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 3.8674 - accuracy: 0.0983 - val_loss: 3.6280 - val_accuracy: 0.1231\n",
      "Epoch 16/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 3.7925 - accuracy: 0.1143 - val_loss: 3.5667 - val_accuracy: 0.1473\n",
      "Epoch 17/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 3.6947 - accuracy: 0.1135 - val_loss: 3.4704 - val_accuracy: 0.1698\n",
      "Epoch 18/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 3.6980 - accuracy: 0.1254 - val_loss: 3.4406 - val_accuracy: 0.1646\n",
      "Epoch 19/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 3.6515 - accuracy: 0.1306 - val_loss: 3.3752 - val_accuracy: 0.1542\n",
      "Epoch 20/30\n",
      "169/169 [==============================] - 27s 162ms/step - loss: 3.5926 - accuracy: 0.1399 - val_loss: 3.3382 - val_accuracy: 0.1768\n",
      "Epoch 21/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 3.5645 - accuracy: 0.1417 - val_loss: 3.2710 - val_accuracy: 0.1872\n",
      "Epoch 22/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 3.5432 - accuracy: 0.1332 - val_loss: 3.3511 - val_accuracy: 0.1785\n",
      "Epoch 23/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 3.5023 - accuracy: 0.1540 - val_loss: 3.2737 - val_accuracy: 0.1854\n",
      "Epoch 24/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 3.4336 - accuracy: 0.1651 - val_loss: 3.2624 - val_accuracy: 0.2010\n",
      "Epoch 25/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 3.3900 - accuracy: 0.1670 - val_loss: 3.2330 - val_accuracy: 0.1802\n",
      "Epoch 26/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 3.3682 - accuracy: 0.1685 - val_loss: 3.1606 - val_accuracy: 0.1889\n",
      "Epoch 27/30\n",
      "169/169 [==============================] - 28s 168ms/step - loss: 3.3653 - accuracy: 0.1685 - val_loss: 3.1373 - val_accuracy: 0.2166\n",
      "Epoch 28/30\n",
      "169/169 [==============================] - 27s 161ms/step - loss: 3.2841 - accuracy: 0.1929 - val_loss: 3.1584 - val_accuracy: 0.2028\n",
      "Epoch 29/30\n",
      "169/169 [==============================] - 29s 170ms/step - loss: 3.2702 - accuracy: 0.1844 - val_loss: 3.0845 - val_accuracy: 0.2132\n",
      "Epoch 30/30\n",
      "169/169 [==============================] - 29s 169ms/step - loss: 3.2332 - accuracy: 0.1911 - val_loss: 3.0853 - val_accuracy: 0.2149\n",
      "19/19 [==============================] - 4s 218ms/step - loss: 2.8969 - accuracy: 0.2318\n",
      "Test accuracy: 0.23183390498161316\n",
      "number of epochs: 30, batch size: 32, optimizer: adam\n",
      "Epoch 1/30\n",
      "85/85 [==============================] - 45s 454ms/step - loss: 4.3903 - accuracy: 0.0627 - val_loss: 4.0212 - val_accuracy: 0.1023\n",
      "Epoch 2/30\n",
      "85/85 [==============================] - 32s 367ms/step - loss: 3.3828 - accuracy: 0.1692 - val_loss: 3.1684 - val_accuracy: 0.1906\n",
      "Epoch 3/30\n",
      "85/85 [==============================] - 25s 299ms/step - loss: 2.8849 - accuracy: 0.2612 - val_loss: 2.8098 - val_accuracy: 0.2790\n",
      "Epoch 4/30\n",
      "85/85 [==============================] - 25s 294ms/step - loss: 2.6588 - accuracy: 0.2801 - val_loss: 2.5447 - val_accuracy: 0.2981\n",
      "Epoch 5/30\n",
      " 6/85 [=>............................] - ETA: 20s - loss: 2.3831 - accuracy: 0.3281"
     ]
    }
   ],
   "source": [
    "# try different models\n",
    "\n",
    "param_grid = {\n",
    "    'model' : ['DenseNet'],\n",
    "    'epochs' : [30,50],\n",
    "    'batch_size': [8,16,32],\n",
    "    'optimizer': ['adam','rmsprop','sgd']}\n",
    "\n",
    "results_training = train_all(param_grid,train_data, train_labels, val_data, val_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675fab8-3c2a-447a-b504-640ec0d870f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21643afc-f412-4b08-b7aa-f7d075d39b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_training_results(results_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15444e49-3b33-4fbc-b358-60b5982b50b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd785f-d5b0-4d16-ad8b-a275778d20a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
