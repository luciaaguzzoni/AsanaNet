{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e3aeb5-dc1d-4c6e-816e-e2ae1613609c",
   "metadata": {},
   "source": [
    "#### Imported Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f68d67d2-b596-4cc1-aa5b-568f4e7dae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img, to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import types\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a642bdd-82b5-4823-b4d2-46923c3ab821",
   "metadata": {},
   "source": [
    "##### constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "457bcb9f-fc22-48c9-96a5-9897b45dc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 100\n",
    "img_width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88b526-0f25-45c1-8aa2-08837ddfef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "747fc58d-b91f-4504-adc1-26412cd1364e",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51413f03-bafa-4607-b2b8-5023f8d2edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_without_squeezing(image, target_size):\n",
    "    h, w = image.shape[:2]\n",
    "    aspect_ratio = w / h\n",
    "\n",
    "    # Calculate new size while preserving aspect ratio\n",
    "    if aspect_ratio > 1:\n",
    "        new_w = target_size\n",
    "        new_h = int(target_size / aspect_ratio)\n",
    "    else:\n",
    "        new_h = target_size\n",
    "        new_w = int(target_size * aspect_ratio)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(image, (new_w, new_h))\n",
    "\n",
    "    # Create a canvas with the target size and fill with padding color\n",
    "    canvas = np.full((target_size, target_size, 3), (255,255,255), dtype=np.uint8)\n",
    "\n",
    "    # Calculate the position to paste the resized image in the center\n",
    "    y_offset = (target_size - new_h) // 2\n",
    "    x_offset = (target_size - new_w) // 2\n",
    "\n",
    "    # Paste the resized image onto the canvas\n",
    "    canvas[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = resized_img\n",
    "\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aaf6a8a-7f33-41fe-8675-b842b4c070a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimg = cv2.imread(\"../data/dataset/salamba sirsasana/55-0.png\")\\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\\n#img = cv2.resize(img, (100, 100))\\nplt.imshow(img)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "img = cv2.imread(\"../data/dataset/salamba sirsasana/55-0.png\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "#img = cv2.resize(img, (100, 100))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dcf947e-db40-4526-a5e8-8406ae512737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimg = cv2.imread(\"../data/dataset/salamba sirsasana/55-0.png\")\\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\\nimg = resize_without_squeezing(img,img_height)\\nplt.imshow(img)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "img = cv2.imread(\"../data/dataset/salamba sirsasana/55-0.png\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "img = resize_without_squeezing(img,img_height)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34e03111-06a2-443c-8e34-0bb3d628646a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images data shape:  (5992, 100, 100, 3)\n",
      "labels data shape:  (5992,)\n"
     ]
    }
   ],
   "source": [
    "def get_folders_in_directory(directory_path):\n",
    "    # Get the list of all files and folders in the specified directory\n",
    "    items = os.listdir(directory_path)\n",
    "    # Filter out only the folders from the list\n",
    "    folders = [item for item in items if os.path.isdir(os.path.join(directory_path, item))]\n",
    "    return folders\n",
    "    \n",
    "def load_images_from_folder(folder):\n",
    "    # Function to load and preprocess images from a folder\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            img = resize_without_squeezing(img,img_height)\n",
    "            #img = cv2.resize(img, (img_height, img_width))\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "\n",
    "base_dir = '../data/dataset'\n",
    "labels_name = get_folders_in_directory(base_dir) # get the list of folder names\n",
    "labels_dict = {label:i for i,label in enumerate(labels_name)} # assign an int for each folder name = asana\n",
    "\n",
    "# Get all images and corresp labels\n",
    "all_images=[]\n",
    "all_labels=[]\n",
    "for label in labels_name:\n",
    "    new_images = load_images_from_folder(base_dir+'/'+label)\n",
    "    all_images = all_images + new_images\n",
    "    for i in range(len(new_images)):\n",
    "        all_labels.append(labels_dict[label])\n",
    "\n",
    "# Ensure that all_image_paths and all_labels are numpy arrays for easier manipulation\n",
    "images = np.array(all_images)/255 # normalize images to the range [0-1]\n",
    "labels = np.array(all_labels)\n",
    "\n",
    "# Shuffle indices\n",
    "indices = np.arange(len(images))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Use the shuffled indices to reorder X and y\n",
    "images_shuffled = images[indices]\n",
    "labels_shuffled = labels[indices]\n",
    "\n",
    "images = images_shuffled\n",
    "labels = labels_shuffled\n",
    "\n",
    "print(\"images data shape: \", images.shape)\n",
    "print(\"labels data shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee03dbe1-c37b-4299-bc95-e2de81deca41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimg = images[700]\\nplt.imshow(img)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "img = images[700]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9a175-bd8b-4bdc-97b5-f36d9272df66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Split Data into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "743987d0-d587-4ca3-8bb0-6b46703618d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTING 1\n",
    "'''\n",
    "# Split the dataset into training and temporary sets (combined validation and test)\n",
    "train_data, temp_data, train_labels, temp_labels = train_test_split(\n",
    "    images, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(\n",
    "    temp_data, temp_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89406d47-6cab-41ae-8eb6-9d4cfa1d207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTING 2\n",
    "# Split the dataset into training and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91851e96-c47a-4ec9-9f2f-bf50c4c6c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# For multi-class classification\n",
    "train_labels_one_hot = to_categorical(train_labels, num_classes=107)\n",
    "#val_labels_one_hot = to_categorical(val_labels, num_classes=107)\n",
    "test_labels_one_hot = to_categorical(test_labels, num_classes=107)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f55a5-66bb-44b5-933c-06f6ec67a3eb",
   "metadata": {},
   "source": [
    "#### Inicialize ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f9a6c8f-4808-444c-831c-19097de8fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "def add_noise(img):\n",
    "    #Add random noise to an image\n",
    "    VARIABILITY = 50\n",
    "    deviation = VARIABILITY*random.random()\n",
    "    noise = np.random.normal(0, deviation, img.shape)\n",
    "    new_img = img + noise\n",
    "    np.clip(new_img, 0., 255.)\n",
    "    return new_img\n",
    "'''\n",
    "\n",
    "# Initialising the ImageDataGenerator class.\n",
    "# We will pass in the augmentation parameters in the constructor.\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range = 30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip = True\n",
    "        #preprocessing_function=add_noise\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59bacf3-6039-4690-a359-7545fa213b57",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b31a2172-2b70-417f-9627-2aa20bc50518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, optimizer, metrics):\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a0ed24-c908-4875-8a13-36698ffb92b8",
   "metadata": {},
   "source": [
    "##### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b32b110d-d772-4e85-84b1-1bfe7cf3a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN():\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(16, (3, 3), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.2), #to avoid overfitting\n",
    "        \n",
    "        layers.Conv2D(32, (3, 3), padding='same',  activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        #layers.Dense(512, activation='relu'), #prova anche 256 e 1024\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(107, activation='softmax') \n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b8d88-b989-4e8e-838c-f34553190145",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1ef615-36f9-47fc-a2b2-3d0c6f9f1dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size=3, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "        self.dropout = layers.Dropout(0.25)\n",
    "        self.conv2 = layers.Conv2D(filters, kernel_size, strides=1, padding='same', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.downsample = None\n",
    "\n",
    "        # Adding a shortcut/skip connection if dimensions change\n",
    "        if stride != 1:\n",
    "            self.downsample = tf.keras.Sequential([\n",
    "                layers.Conv2D(filters, 1, strides=stride, use_bias=False),\n",
    "                layers.BatchNormalization()\n",
    "            ])\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        residual = inputs\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "\n",
    "        # Adding the skip connection if present\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(residual)\n",
    "\n",
    "        x += residual\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(64, 3, strides=2, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "        self.pool1 = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')\n",
    "\n",
    "        self.block1 = ResidualBlock(64)\n",
    "        self.block2 = ResidualBlock(64)\n",
    "        \n",
    "\n",
    "        self.global_avg_pooling = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.block1(x, training=training)\n",
    "        x = self.block2(x, training=training)\n",
    "        # Add more blocks as needed...\n",
    "\n",
    "        x = self.global_avg_pooling(x)\n",
    "        output = self.fc(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2035ba8a-62e9-4915-a888-7fdf93d7c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ResNet model\n",
    "num_classes = 107  # Set the number of classes based on your task\n",
    "resnet_model = ResNet(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877ad228-1261-4157-834b-66dad424ddb6",
   "metadata": {},
   "source": [
    "##### DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fb163c2-667f-4794-9aae-62445bd40e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DN():\n",
    "    ptrain_model = tf.keras.applications.DenseNet121(input_shape=(img_height,img_width,3),\n",
    "                                                      include_top=False,\n",
    "                                                      weights='imagenet',\n",
    "                                                      pooling='avg')\n",
    "    ptrain_model.trainable = False\n",
    "    \n",
    "    inputs = ptrain_model.input\n",
    "    \n",
    "    drop_layer = tf.keras.layers.Dropout(0.25)(ptrain_model.output)\n",
    "    x_layer = tf.keras.layers.Dense(512, activation='relu')(drop_layer)\n",
    "    x_layer1 = tf.keras.layers.Dense(128, activation='relu')(x_layer)\n",
    "    drop_layer1 = tf.keras.layers.Dropout(0.20)(x_layer1)\n",
    "    outputs = tf.keras.layers.Dense(107, activation='softmax')(drop_layer1)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "                  \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735de6d6-d44b-4060-8594-9f43c202fe69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79d058-bbb8-4e10-8ed0-0a9414157220",
   "metadata": {},
   "source": [
    "- Popular CNN architectures include:\n",
    "\n",
    "AlexNet <br>\n",
    "VGGNet <br>\n",
    "GoogLeNet (Inception) <br>\n",
    "ResNet <br>\n",
    "MobileNet\n",
    "\n",
    "- Popular pre-trained models include: (Consider using pre-trained models like InceptionV3, ResNet50, or MobileNetV2 and fine-tuning them on your dataset.)\r\n",
    "\r\n",
    "Inception <br>V3\r\n",
    "ResNe <br>t50\r\n",
    "MobileN <br>etV2\r\n",
    "Xce <br>ption\r\n",
    "Effici <br>entNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92129421-1fd9-41ff-b775-56bc7322039a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46e326e3-f40d-478c-a82a-e59bdac11439",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=10000, decay_rate=0.9, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "# possible optimizer : rmsprop, adam, SGD\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#resnet_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f83ee-ec0a-4f0c-a52c-cb07fa807d85",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a2c34-c99b-4cb6-9c55-e4bd41fa7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with data augmentation\n",
    "batch_size = 16 # number of training examples utilized in one iteration\n",
    "num_epochs = 10 # number of iteration\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1, verbose=1, patience = 4)\n",
    "\n",
    "# Use flow for the training set\n",
    "train_datagen = datagen.flow(train_data, train_labels_one_hot, batch_size=batch_size)\n",
    "# Use flow for the validation set\n",
    "#val_datagen = datagen.flow(val_data, val_labels_one_hot, batch_size=batch_size)\n",
    "\n",
    "# Train the model with data augmentation\n",
    "history = model.fit(train_datagen, epochs=num_epochs, validation_split=0.3, callback=[es])\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels_one_hot)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "plt.plot(history.history['accuracy'],label='train')\n",
    "plt.plot(history.history['val_accuracy'], labek='test')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c41ac751-6aad-491c-89ca-aaf5001ba42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8eec1d-b752-4c29-9920-c637ef8acd9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7e16757-34d1-43e2-a357-447c0f1c3776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "150/150 [==============================] - 15s 87ms/step - loss: 4.6670 - accuracy: 0.0165 - val_loss: 4.6228 - val_accuracy: 0.0134\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 4.4801 - accuracy: 0.0353 - val_loss: 4.4190 - val_accuracy: 0.0568\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 4.2858 - accuracy: 0.0515 - val_loss: 4.2472 - val_accuracy: 0.0618\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 4.1805 - accuracy: 0.0588 - val_loss: 4.1744 - val_accuracy: 0.0634\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 4.0941 - accuracy: 0.0693 - val_loss: 4.1014 - val_accuracy: 0.0801\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 4.0078 - accuracy: 0.0778 - val_loss: 4.0124 - val_accuracy: 0.0902\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 3.9541 - accuracy: 0.0914 - val_loss: 3.9391 - val_accuracy: 0.1018\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 3.9013 - accuracy: 0.0903 - val_loss: 3.9176 - val_accuracy: 0.0985\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 3.8292 - accuracy: 0.0970 - val_loss: 3.9078 - val_accuracy: 0.0985\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 3.8038 - accuracy: 0.0995 - val_loss: 3.8544 - val_accuracy: 0.0985\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 3.7671 - accuracy: 0.1104 - val_loss: 3.9159 - val_accuracy: 0.1002\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 3.7341 - accuracy: 0.1173 - val_loss: 3.8327 - val_accuracy: 0.1085\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 3.6870 - accuracy: 0.1187 - val_loss: 3.8712 - val_accuracy: 0.1152\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - 14s 96ms/step - loss: 3.6515 - accuracy: 0.1260 - val_loss: 3.7244 - val_accuracy: 0.1185\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 3.6741 - accuracy: 0.1260 - val_loss: 3.7680 - val_accuracy: 0.1102\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 3.6395 - accuracy: 0.1271 - val_loss: 3.7227 - val_accuracy: 0.1586\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 3.6128 - accuracy: 0.1335 - val_loss: 3.8424 - val_accuracy: 0.1185\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 3.5732 - accuracy: 0.1425 - val_loss: 3.8316 - val_accuracy: 0.1235\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 3.5565 - accuracy: 0.1364 - val_loss: 3.6672 - val_accuracy: 0.1486\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 3.5591 - accuracy: 0.1440 - val_loss: 3.7672 - val_accuracy: 0.1285\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 3.5270 - accuracy: 0.1554 - val_loss: 3.7629 - val_accuracy: 0.1269\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 3.5204 - accuracy: 0.1408 - val_loss: 3.7038 - val_accuracy: 0.1586\n",
      "Epoch 23/30\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 3.4798 - accuracy: 0.1513 - val_loss: 3.6891 - val_accuracy: 0.1386\n",
      "Epoch 24/30\n",
      "150/150 [==============================] - 13s 88ms/step - loss: 3.4927 - accuracy: 0.1640 - val_loss: 3.6971 - val_accuracy: 0.1419\n",
      "Epoch 25/30\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 3.4598 - accuracy: 0.1621 - val_loss: 3.6067 - val_accuracy: 0.1720\n",
      "Epoch 26/30\n",
      "150/150 [==============================] - 14s 94ms/step - loss: 3.4254 - accuracy: 0.1659 - val_loss: 3.6544 - val_accuracy: 0.1369\n",
      "Epoch 27/30\n",
      "150/150 [==============================] - 15s 98ms/step - loss: 3.4275 - accuracy: 0.1629 - val_loss: 3.5818 - val_accuracy: 0.1636\n",
      "Epoch 28/30\n",
      "150/150 [==============================] - 16s 108ms/step - loss: 3.4027 - accuracy: 0.1652 - val_loss: 3.6122 - val_accuracy: 0.1569\n",
      "Epoch 29/30\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 3.3979 - accuracy: 0.1692 - val_loss: 3.6875 - val_accuracy: 0.1519\n",
      "Epoch 30/30\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 3.3583 - accuracy: 0.1757 - val_loss: 3.5817 - val_accuracy: 0.1436\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 3.1137 - accuracy: 0.2850\n",
      "Test accuracy: 0.2849999964237213\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 30\n",
    "# image_size = 100x100\n",
    "# no noise added\n",
    "# optimizer: adam\n",
    "# without layers.Dense(512, activation='relu')\n",
    "\n",
    "train_datagen = datagen.flow(train_data, train_labels_one_hot, batch_size=batch_size)\n",
    "val_datagen = datagen.flow(val_data, val_labels_one_hot, batch_size=batch_size)\n",
    "history = model.fit(train_datagen, epochs=num_epochs, validation_data=val_datagen)\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels_one_hot)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44af7986-396f-48b7-bdf7-387569c8eb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "150/150 [==============================] - 14s 85ms/step - loss: 4.6436 - accuracy: 0.0169 - val_loss: 4.5404 - val_accuracy: 0.0267\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - 13s 83ms/step - loss: 4.4024 - accuracy: 0.0390 - val_loss: 4.3252 - val_accuracy: 0.0434\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 4.2708 - accuracy: 0.0469 - val_loss: 4.2310 - val_accuracy: 0.0601\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.1826 - accuracy: 0.0574 - val_loss: 4.1810 - val_accuracy: 0.0668\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.1232 - accuracy: 0.0649 - val_loss: 4.1243 - val_accuracy: 0.0902\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.0562 - accuracy: 0.0741 - val_loss: 4.1052 - val_accuracy: 0.0785\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 3.9955 - accuracy: 0.0864 - val_loss: 4.0167 - val_accuracy: 0.0885\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.9300 - accuracy: 0.0972 - val_loss: 3.9240 - val_accuracy: 0.0902\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.8621 - accuracy: 0.1066 - val_loss: 3.8522 - val_accuracy: 0.1135\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.8404 - accuracy: 0.1189 - val_loss: 3.9023 - val_accuracy: 0.0985\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 3.7970 - accuracy: 0.1137 - val_loss: 3.8456 - val_accuracy: 0.1135\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.7727 - accuracy: 0.1239 - val_loss: 3.8458 - val_accuracy: 0.1052\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.7461 - accuracy: 0.1233 - val_loss: 3.7404 - val_accuracy: 0.1336\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 3.6884 - accuracy: 0.1252 - val_loss: 3.8133 - val_accuracy: 0.1202\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.6982 - accuracy: 0.1321 - val_loss: 3.7877 - val_accuracy: 0.1252\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 3.6754 - accuracy: 0.1325 - val_loss: 3.7105 - val_accuracy: 0.1269\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 3.6489 - accuracy: 0.1427 - val_loss: 3.7622 - val_accuracy: 0.1169\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.6439 - accuracy: 0.1360 - val_loss: 3.7372 - val_accuracy: 0.1202\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.6431 - accuracy: 0.1350 - val_loss: 3.8842 - val_accuracy: 0.1035\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 3.5789 - accuracy: 0.1531 - val_loss: 3.7231 - val_accuracy: 0.1336\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.5797 - accuracy: 0.1492 - val_loss: 3.7272 - val_accuracy: 0.1302\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.5726 - accuracy: 0.1577 - val_loss: 3.7180 - val_accuracy: 0.1369\n",
      "Epoch 23/30\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 3.5691 - accuracy: 0.1542 - val_loss: 3.6538 - val_accuracy: 0.1486\n",
      "Epoch 24/30\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.5503 - accuracy: 0.1525 - val_loss: 3.5862 - val_accuracy: 0.1736\n",
      "Epoch 25/30\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 3.5412 - accuracy: 0.1602 - val_loss: 3.6200 - val_accuracy: 0.1369\n",
      "Epoch 26/30\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 3.5188 - accuracy: 0.1607 - val_loss: 3.6894 - val_accuracy: 0.1219\n",
      "Epoch 27/30\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 3.5017 - accuracy: 0.1646 - val_loss: 3.6215 - val_accuracy: 0.1402\n",
      "Epoch 28/30\n",
      "150/150 [==============================] - 13s 89ms/step - loss: 3.4832 - accuracy: 0.1700 - val_loss: 3.6614 - val_accuracy: 0.1319\n",
      "Epoch 29/30\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 3.4762 - accuracy: 0.1732 - val_loss: 3.5262 - val_accuracy: 0.1603\n",
      "Epoch 30/30\n",
      "150/150 [==============================] - 13s 87ms/step - loss: 3.4668 - accuracy: 0.1719 - val_loss: 3.5692 - val_accuracy: 0.1669\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 30\n",
    "# image_size = 100x100\n",
    "# no noise added\n",
    "# optimizer: rmsprop\n",
    "# without layers.Dense(512, activation='relu')\n",
    "\n",
    "train_datagen = datagen.flow(train_data, train_labels_one_hot, batch_size=batch_size)\n",
    "val_datagen = datagen.flow(val_data, val_labels_one_hot, batch_size=batch_size)\n",
    "history = model.fit(train_datagen, epochs=num_epochs, validation_data=val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "740460b1-8301-49cd-b0b0-eac2274ca2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 14ms/step - loss: 2.9677 - accuracy: 0.2833\n",
      "Test accuracy: 0.28333333134651184\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data, test_labels_one_hot)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f61cd-fc4b-448b-aca6-7eecd0a4b51c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ad43cb-5c3c-4144-8778-061a278511e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "150/150 [==============================] - 21s 129ms/step - loss: 4.5829 - accuracy: 0.0292 - val_loss: 5.4102 - val_accuracy: 0.0117\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - 20s 130ms/step - loss: 4.2674 - accuracy: 0.0465 - val_loss: 5.4436 - val_accuracy: 0.0134\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - 20s 134ms/step - loss: 4.1130 - accuracy: 0.0488 - val_loss: 7.7326 - val_accuracy: 0.0184\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - 21s 138ms/step - loss: 4.0074 - accuracy: 0.0620 - val_loss: 6.1084 - val_accuracy: 0.0250\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - 22s 148ms/step - loss: 3.9432 - accuracy: 0.0670 - val_loss: 4.1867 - val_accuracy: 0.0501\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - 21s 142ms/step - loss: 3.8879 - accuracy: 0.0784 - val_loss: 5.6141 - val_accuracy: 0.0134\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 3.8366 - accuracy: 0.0841 - val_loss: 7.9083 - val_accuracy: 0.0167\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - 22s 144ms/step - loss: 3.7905 - accuracy: 0.0916 - val_loss: 5.6341 - val_accuracy: 0.0250\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - 22s 144ms/step - loss: 3.7215 - accuracy: 0.1081 - val_loss: 4.7392 - val_accuracy: 0.0367\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - 23s 154ms/step - loss: 3.6738 - accuracy: 0.1060 - val_loss: 6.8257 - val_accuracy: 0.0200\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - 23s 151ms/step - loss: 3.6292 - accuracy: 0.1191 - val_loss: 4.5674 - val_accuracy: 0.0584\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - 21s 142ms/step - loss: 3.5673 - accuracy: 0.1275 - val_loss: 5.7777 - val_accuracy: 0.0301\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - 21s 142ms/step - loss: 3.5472 - accuracy: 0.1342 - val_loss: 5.2954 - val_accuracy: 0.0384\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - 21s 142ms/step - loss: 3.5230 - accuracy: 0.1385 - val_loss: 4.2376 - val_accuracy: 0.0718\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 3.4510 - accuracy: 0.1527 - val_loss: 4.5212 - val_accuracy: 0.0551\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - 22s 145ms/step - loss: 3.4100 - accuracy: 0.1561 - val_loss: 7.5097 - val_accuracy: 0.0284\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - 22s 144ms/step - loss: 3.3598 - accuracy: 0.1753 - val_loss: 3.8359 - val_accuracy: 0.0935\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - 23s 151ms/step - loss: 3.3377 - accuracy: 0.1738 - val_loss: 6.9578 - val_accuracy: 0.0334\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - 23s 150ms/step - loss: 3.2858 - accuracy: 0.1738 - val_loss: 3.9920 - val_accuracy: 0.0768\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - 24s 161ms/step - loss: 3.2617 - accuracy: 0.1907 - val_loss: 4.0490 - val_accuracy: 0.0918\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - 24s 157ms/step - loss: 3.2180 - accuracy: 0.2009 - val_loss: 5.6504 - val_accuracy: 0.0334\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - 22s 149ms/step - loss: 3.2006 - accuracy: 0.1978 - val_loss: 5.0778 - val_accuracy: 0.0618\n",
      "Epoch 23/30\n",
      "150/150 [==============================] - 23s 152ms/step - loss: 3.1617 - accuracy: 0.2061 - val_loss: 4.1767 - val_accuracy: 0.0768\n",
      "Epoch 24/30\n",
      "150/150 [==============================] - 23s 152ms/step - loss: 3.1305 - accuracy: 0.2103 - val_loss: 6.6871 - val_accuracy: 0.0334\n",
      "Epoch 25/30\n",
      "150/150 [==============================] - 22s 149ms/step - loss: 3.0970 - accuracy: 0.2143 - val_loss: 4.3908 - val_accuracy: 0.0584\n",
      "Epoch 26/30\n",
      "150/150 [==============================] - 24s 160ms/step - loss: 3.0753 - accuracy: 0.2174 - val_loss: 3.7808 - val_accuracy: 0.1336\n",
      "Epoch 27/30\n",
      "150/150 [==============================] - 25s 165ms/step - loss: 3.0100 - accuracy: 0.2305 - val_loss: 9.2885 - val_accuracy: 0.0467\n",
      "Epoch 28/30\n",
      "150/150 [==============================] - 24s 159ms/step - loss: 3.0049 - accuracy: 0.2257 - val_loss: 5.6034 - val_accuracy: 0.0568\n",
      "Epoch 29/30\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 2.9640 - accuracy: 0.2406 - val_loss: 9.6463 - val_accuracy: 0.0250\n",
      "Epoch 30/30\n",
      "150/150 [==============================] - 23s 154ms/step - loss: 2.9324 - accuracy: 0.2458 - val_loss: 3.7295 - val_accuracy: 0.0968\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 3.4746 - accuracy: 0.1500\n",
      "Test accuracy: 0.15000000596046448\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 30 \n",
    "# image_size = 100x100\n",
    "# no noise added\n",
    "# optimizer: adam\n",
    "\n",
    "train_datagen = datagen.flow(train_data, train_labels_one_hot, batch_size=batch_size)\n",
    "val_datagen = datagen.flow(val_data, val_labels_one_hot, batch_size=batch_size)\n",
    "history = resnet_model.fit(train_datagen, epochs=num_epochs, validation_data=val_datagen)\n",
    "test_loss, test_acc = resnet_model.evaluate(test_data, test_labels_one_hot)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "102072dc-52fb-417c-8b1d-63e7f93d5e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "150/150 [==============================] - 22s 135ms/step - loss: 4.5804 - accuracy: 0.0257 - val_loss: 5.4785 - val_accuracy: 0.0200\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - 21s 136ms/step - loss: 4.2501 - accuracy: 0.0482 - val_loss: 6.3911 - val_accuracy: 0.0217\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - 21s 138ms/step - loss: 4.0890 - accuracy: 0.0570 - val_loss: 4.9307 - val_accuracy: 0.0267\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - 23s 150ms/step - loss: 3.9878 - accuracy: 0.0672 - val_loss: 7.3067 - val_accuracy: 0.0184\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - 21s 137ms/step - loss: 3.9121 - accuracy: 0.0770 - val_loss: 5.5572 - val_accuracy: 0.0200\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - 22s 143ms/step - loss: 3.8564 - accuracy: 0.0874 - val_loss: 4.6914 - val_accuracy: 0.0334\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - 22s 145ms/step - loss: 3.8021 - accuracy: 0.0935 - val_loss: 4.7797 - val_accuracy: 0.0434\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - 22s 144ms/step - loss: 3.7483 - accuracy: 0.1089 - val_loss: 4.2756 - val_accuracy: 0.0634\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - 22s 148ms/step - loss: 3.6969 - accuracy: 0.1133 - val_loss: 6.2001 - val_accuracy: 0.0334\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - 22s 145ms/step - loss: 3.6470 - accuracy: 0.1256 - val_loss: 5.5568 - val_accuracy: 0.0301\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - 22s 146ms/step - loss: 3.6038 - accuracy: 0.1235 - val_loss: 5.1847 - val_accuracy: 0.0417\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - 22s 144ms/step - loss: 3.5543 - accuracy: 0.1367 - val_loss: 4.1950 - val_accuracy: 0.0518\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - 21s 142ms/step - loss: 3.5172 - accuracy: 0.1417 - val_loss: 7.6106 - val_accuracy: 0.0250\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - 21s 139ms/step - loss: 3.4792 - accuracy: 0.1488 - val_loss: 9.6763 - val_accuracy: 0.0334\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 3.4440 - accuracy: 0.1552 - val_loss: 4.1649 - val_accuracy: 0.0785\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - 21s 140ms/step - loss: 3.3952 - accuracy: 0.1669 - val_loss: 4.6658 - val_accuracy: 0.0434\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 3.3465 - accuracy: 0.1702 - val_loss: 3.8994 - val_accuracy: 0.1169\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - 22s 148ms/step - loss: 3.3199 - accuracy: 0.1807 - val_loss: 3.7359 - val_accuracy: 0.0868\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - 22s 145ms/step - loss: 3.2908 - accuracy: 0.1771 - val_loss: 5.0502 - val_accuracy: 0.0401\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - 22s 145ms/step - loss: 3.2583 - accuracy: 0.1878 - val_loss: 11.1994 - val_accuracy: 0.0234\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - 22s 149ms/step - loss: 3.2131 - accuracy: 0.2051 - val_loss: 6.1156 - val_accuracy: 0.0417\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - 22s 149ms/step - loss: 3.1829 - accuracy: 0.2024 - val_loss: 3.6014 - val_accuracy: 0.1068\n",
      "Epoch 23/30\n",
      "150/150 [==============================] - 23s 151ms/step - loss: 3.1342 - accuracy: 0.2082 - val_loss: 5.5510 - val_accuracy: 0.0518\n",
      "Epoch 24/30\n",
      "150/150 [==============================] - 23s 151ms/step - loss: 3.0985 - accuracy: 0.2197 - val_loss: 4.9953 - val_accuracy: 0.0434\n",
      "Epoch 25/30\n",
      "150/150 [==============================] - 22s 148ms/step - loss: 3.0852 - accuracy: 0.2214 - val_loss: 3.8961 - val_accuracy: 0.1002\n",
      "Epoch 26/30\n",
      "150/150 [==============================] - 22s 145ms/step - loss: 3.0537 - accuracy: 0.2278 - val_loss: 5.7355 - val_accuracy: 0.0317\n",
      "Epoch 27/30\n",
      "150/150 [==============================] - 22s 143ms/step - loss: 3.0241 - accuracy: 0.2305 - val_loss: 6.5008 - val_accuracy: 0.0401\n",
      "Epoch 28/30\n",
      "150/150 [==============================] - 22s 143ms/step - loss: 3.0044 - accuracy: 0.2364 - val_loss: 5.1455 - val_accuracy: 0.0701\n",
      "Epoch 29/30\n",
      "150/150 [==============================] - 22s 143ms/step - loss: 2.9663 - accuracy: 0.2468 - val_loss: 6.5075 - val_accuracy: 0.0584\n",
      "Epoch 30/30\n",
      "150/150 [==============================] - 22s 143ms/step - loss: 2.9567 - accuracy: 0.2510 - val_loss: 5.2272 - val_accuracy: 0.0551\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 5.1198 - accuracy: 0.0733\n",
      "Test accuracy: 0.07333333045244217\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 30 \n",
    "# image_size = 100x100\n",
    "# no noise added\n",
    "# optimizer: rmsprop\n",
    "\n",
    "train_datagen = datagen.flow(train_data, train_labels_one_hot, batch_size=batch_size)\n",
    "val_datagen = datagen.flow(val_data, val_labels_one_hot, batch_size=batch_size)\n",
    "history = resnet_model.fit(train_datagen, epochs=num_epochs, validation_data=val_datagen)\n",
    "test_loss, test_acc = resnet_model.evaluate(test_data, test_labels_one_hot)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668b792-699c-4407-a840-db3b2866de89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac303731-1637-4a44-85b9-edd908033b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126697ce-ba2d-4fe9-b715-e5166ecade02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42255efa-fea7-4c5c-bd7b-6a950284e492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bdd0c9-846f-44d4-90ca-76b67d76e363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736b406-9c22-46d6-85d6-ee7a0b2f515a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "759edcc8-a9d3-4483-a5c9-b1d3c0085218",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### DenseSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fe56f47-3aa5-4b32-9bbe-125c50b6837e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "150/150 [==============================] - 51s 298ms/step - loss: 4.6963 - accuracy: 0.0142 - val_loss: 4.5425 - val_accuracy: 0.0250\n",
      "Epoch 2/30\n",
      "150/150 [==============================] - 47s 308ms/step - loss: 4.4214 - accuracy: 0.0388 - val_loss: 4.1213 - val_accuracy: 0.0684\n",
      "Epoch 3/30\n",
      "150/150 [==============================] - 46s 309ms/step - loss: 4.0352 - accuracy: 0.0753 - val_loss: 3.6939 - val_accuracy: 0.1085\n",
      "Epoch 4/30\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 3.7361 - accuracy: 0.0991 - val_loss: 3.4252 - val_accuracy: 0.1436\n",
      "Epoch 5/30\n",
      "150/150 [==============================] - 43s 287ms/step - loss: 3.5636 - accuracy: 0.1258 - val_loss: 3.3379 - val_accuracy: 0.1770\n",
      "Epoch 6/30\n",
      "150/150 [==============================] - 45s 297ms/step - loss: 3.3902 - accuracy: 0.1496 - val_loss: 3.1710 - val_accuracy: 0.1836\n",
      "Epoch 7/30\n",
      "150/150 [==============================] - 45s 302ms/step - loss: 3.2736 - accuracy: 0.1707 - val_loss: 3.0279 - val_accuracy: 0.2170\n",
      "Epoch 8/30\n",
      "150/150 [==============================] - 48s 323ms/step - loss: 3.2050 - accuracy: 0.1840 - val_loss: 2.9960 - val_accuracy: 0.2237\n",
      "Epoch 9/30\n",
      "150/150 [==============================] - 46s 309ms/step - loss: 3.1413 - accuracy: 0.2024 - val_loss: 2.9747 - val_accuracy: 0.2387\n",
      "Epoch 10/30\n",
      "150/150 [==============================] - 44s 295ms/step - loss: 3.0471 - accuracy: 0.2180 - val_loss: 2.9073 - val_accuracy: 0.2254\n",
      "Epoch 11/30\n",
      "150/150 [==============================] - 46s 305ms/step - loss: 3.0154 - accuracy: 0.2268 - val_loss: 2.8299 - val_accuracy: 0.2571\n",
      "Epoch 12/30\n",
      "150/150 [==============================] - 45s 297ms/step - loss: 2.9658 - accuracy: 0.2339 - val_loss: 2.8011 - val_accuracy: 0.2588\n",
      "Epoch 13/30\n",
      "150/150 [==============================] - 46s 302ms/step - loss: 2.8996 - accuracy: 0.2422 - val_loss: 2.7529 - val_accuracy: 0.2705\n",
      "Epoch 14/30\n",
      "150/150 [==============================] - 46s 303ms/step - loss: 2.8355 - accuracy: 0.2600 - val_loss: 2.6918 - val_accuracy: 0.3088\n",
      "Epoch 15/30\n",
      "150/150 [==============================] - 47s 314ms/step - loss: 2.8398 - accuracy: 0.2591 - val_loss: 2.7036 - val_accuracy: 0.2938\n",
      "Epoch 16/30\n",
      "150/150 [==============================] - 47s 311ms/step - loss: 2.7702 - accuracy: 0.2668 - val_loss: 2.7321 - val_accuracy: 0.2738\n",
      "Epoch 17/30\n",
      "150/150 [==============================] - 48s 321ms/step - loss: 2.7662 - accuracy: 0.2800 - val_loss: 2.6540 - val_accuracy: 0.3255\n",
      "Epoch 18/30\n",
      "150/150 [==============================] - 45s 300ms/step - loss: 2.7395 - accuracy: 0.2712 - val_loss: 2.7055 - val_accuracy: 0.2988\n",
      "Epoch 19/30\n",
      "150/150 [==============================] - 46s 304ms/step - loss: 2.7020 - accuracy: 0.2858 - val_loss: 2.6529 - val_accuracy: 0.3088\n",
      "Epoch 20/30\n",
      "150/150 [==============================] - 46s 308ms/step - loss: 2.6631 - accuracy: 0.2925 - val_loss: 2.6667 - val_accuracy: 0.3139\n",
      "Epoch 21/30\n",
      "150/150 [==============================] - 45s 303ms/step - loss: 2.6325 - accuracy: 0.3021 - val_loss: 2.6894 - val_accuracy: 0.2972\n",
      "Epoch 22/30\n",
      "150/150 [==============================] - 46s 306ms/step - loss: 2.6041 - accuracy: 0.3071 - val_loss: 2.6433 - val_accuracy: 0.3255\n",
      "Epoch 23/30\n",
      "150/150 [==============================] - 46s 306ms/step - loss: 2.5815 - accuracy: 0.3167 - val_loss: 2.6100 - val_accuracy: 0.3005\n",
      "Epoch 24/30\n",
      "150/150 [==============================] - 46s 308ms/step - loss: 2.5738 - accuracy: 0.3111 - val_loss: 2.6100 - val_accuracy: 0.3155\n",
      "Epoch 25/30\n",
      "150/150 [==============================] - 48s 319ms/step - loss: 2.5640 - accuracy: 0.3196 - val_loss: 2.6139 - val_accuracy: 0.3072\n",
      "Epoch 26/30\n",
      "150/150 [==============================] - 47s 311ms/step - loss: 2.5211 - accuracy: 0.3192 - val_loss: 2.5632 - val_accuracy: 0.3155\n",
      "Epoch 27/30\n",
      "150/150 [==============================] - 49s 323ms/step - loss: 2.4930 - accuracy: 0.3296 - val_loss: 2.5927 - val_accuracy: 0.3072\n",
      "Epoch 28/30\n",
      "150/150 [==============================] - 46s 309ms/step - loss: 2.4532 - accuracy: 0.3315 - val_loss: 2.6330 - val_accuracy: 0.3055\n",
      "Epoch 29/30\n",
      "150/150 [==============================] - 46s 308ms/step - loss: 2.4561 - accuracy: 0.3395 - val_loss: 2.5792 - val_accuracy: 0.3055\n",
      "Epoch 30/30\n",
      "150/150 [==============================] - 47s 310ms/step - loss: 2.4352 - accuracy: 0.3472 - val_loss: 2.5943 - val_accuracy: 0.3189\n",
      "19/19 [==============================] - 5s 249ms/step - loss: 2.4169 - accuracy: 0.3517\n",
      "Test accuracy: 0.351666659116745\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 30 \n",
    "# image_size = 100x100\n",
    "# no noise added\n",
    "# optimizer: adam\n",
    "\n",
    "train_datagen = datagen.flow(train_data, train_labels_one_hot, batch_size=batch_size)\n",
    "val_datagen = datagen.flow(val_data, val_labels_one_hot, batch_size=batch_size)\n",
    "history = model.fit(train_datagen, epochs=num_epochs, validation_data=val_datagen)\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels_one_hot)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be178c-a6ae-46b9-be34-13ee0e0a8035",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3081ea-e700-4b7d-a486-1fd3893e5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896d752-a6a2-4505-8566-c7241ef0d010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23acd8a2-5416-4b34-ae27-12d4560fe8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b598191-13ed-4120-b1cf-1a6776818126",
   "metadata": {},
   "source": [
    "### Compare Models and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cea6e8c0-244b-4800-bbd0-ffe7b7da2abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# SPLITTING 2\\ntrain_data, test_data, train_labels, test_labels = train_test_split(\\n    images, labels, test_size=0.2, random_state=42\\n)\\ntrain_labels_one_hot = to_categorical(train_labels, num_classes=107)\\ntest_labels_one_hot = to_categorical(test_labels, num_classes=107)\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SPLITTING 1\n",
    "# Split the dataset into training and temporary sets (combined validation and test)\n",
    "train_data, temp_data, train_labels, temp_labels = train_test_split(\n",
    "    images, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(\n",
    "    temp_data, temp_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "train_labels_one_hot = to_categorical(train_labels, num_classes=107)\n",
    "val_labels_one_hot = to_categorical(val_labels, num_classes=107)\n",
    "test_labels_one_hot = to_categorical(test_labels, num_classes=107)\n",
    "\n",
    "\n",
    "'''\n",
    "# SPLITTING 2\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "train_labels_one_hot = to_categorical(train_labels, num_classes=107)\n",
    "test_labels_one_hot = to_categorical(test_labels, num_classes=107)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e554cab4-911e-41de-ac9d-805cb755df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, val_data, test_data, train_labels_one_hot, val_labels_one_hot, test_labels_one_hot, model, optimizer, batch_size, num_epochs, metrics=['accuracy']):\n",
    "\n",
    "    # optimizer\n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=10000, decay_rate=0.9, staircase=True)\n",
    "    if optimizer=='adam':\n",
    "        opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    elif optimizer=='rmsprop':\n",
    "        opt = keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "    elif optimizer=='SGD':\n",
    "        opt = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "    # compile model\n",
    "    model = compile_model(model, opt, metrics)\n",
    "\n",
    "    # train model\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1, verbose=1, patience = 4)\n",
    "\n",
    "    train_datagen = datagen.flow(train_data, train_labels_one_hot, batch_size=batch_size)\n",
    "    val_datagen = datagen.flow(val_data, val_labels_one_hot, batch_size=batch_size)\n",
    "    history = cnn_model.fit(train_datagen, epochs=num_epochs, validation_data=val_datagen, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_acc = model.evaluate(test_data, test_labels_one_hot)\n",
    "    print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "    plt.plot(history.history['accuracy'],label='train')\n",
    "    plt.plot(history.history['val_accuracy'], label='test')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d203e3-8d1f-4c4a-81fe-f7923212b689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af1386-1afe-462e-93df-3d2805e2a8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c77178-2bab-4de5-a86a-36b7f11a4591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda1afc-1648-4d94-9e22-20922e4c6150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e33b4-3a2d-4d80-bb3f-a3230836014b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbba88-f430-4407-8b6c-0bf9003d8355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a910dba-a32e-4754-908b-8aef30f56749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4755f-450b-45b1-90c2-e59f74fded67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0ba83-12c4-48d1-a3e0-1104d727635e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab925c13-c790-484e-b0ba-6b2f9debcdbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c4d89-e304-42db-a7c2-fb3ff172ead9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf848e-b6d7-4355-be95-1f328e548e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c08e49-f950-45af-852e-ab2fd4f5cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaeee42-eff4-4df3-9748-875766945bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecbd752-05b9-4f5a-af5a-330cd2955183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d184a1d-f1c9-473c-9129-f0d9f5db2c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24868309-0a75-405e-bb81-30a2c4445e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ca2c3-8fe4-48e9-bea5-8e95a4841825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3021f52-66ca-4c41-b4ca-0ce6bb000647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da642608-4003-4b57-b7ba-a69f265c93e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965593e-d362-46a6-9770-55e24b31fee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a72b4-e006-4ad7-a3ee-329492dfa1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ccbd01-e71e-48ad-872a-e3452569898b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda6ea7-a4a8-4862-b0b9-9ffff99982b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f1343-2665-47f6-81e5-4a12d89f3887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b2c5f-c15e-442f-85d9-617ebdb7ef27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6330502-8a42-4711-9408-eb921d083961",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 135 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n135 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1491, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 760, in fit\n    self._fit(\n  File \"C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 926, in _fit\n    self._check_model_compatibility(y)\n  File \"C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 549, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: object of type 'NoneType' has no len()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m KerasClassifier(create_CNN)\n\u001b[0;32m     14\u001b[0m grid_cnn \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mcnn_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_cnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_one_hot\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_cnn\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters for CNN are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 135 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n135 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1491, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 760, in fit\n    self._fit(\n  File \"C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 926, in _fit\n    self._check_model_compatibility(y)\n  File \"C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 549, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: object of type 'NoneType' has no len()\n"
     ]
    }
   ],
   "source": [
    "initial_learning_rate = 0.001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=10000, decay_rate=0.9, staircase=True\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'epochs' : [30,50,70],\n",
    "    'batch_size': [8,16,32],\n",
    "    'optimizer': ['Adam','SGD','RMSprop']\n",
    "}\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1, verbose=1, patience = 4)\n",
    "\n",
    "cnn_model = KerasClassifier(create_CNN)\n",
    "grid_cnn = GridSearchCV(estimator=cnn_model, param_grid=param_grid, scoring='accuracy')\n",
    "grid_result = grid_cnn.fit(train_data, train_labels_one_hot , validation_split=0.3, callbacks=early_stopping)\n",
    "best_params = grid_cnn.best_params\n",
    "print(f\"Best Hyperparameters for CNN are: {best_params}\")\n",
    "\n",
    "\n",
    "'''\n",
    "dn_model = KerasClassifier(create_DN)\n",
    "grid_dn = GridSearchCV(estimator= create_DN(), param_grid=param_grid, scoring=['accuracy'])\n",
    "grid_result = grid_dn.fit(train_datagen, validation_split=0.3, callback=[es])\n",
    "best_params = grid_dn.best_params\n",
    "print(f\"Best Hyperparameters for DenseNet are: {best_params}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210b935-b74a-43ea-8fdd-b8be023ef340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c252d34-2e13-4b7f-8011-38599ac48255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f6ee5-2aea-4676-95a5-d70c9ef77045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9705599-1745-46cf-8996-ab43c8bf07d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50ad07-e0ef-42b3-a4f2-34fae0a2ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_asana(n):\n",
    "    lista=[]\n",
    "    for el in n:\n",
    "        l=[key for key, value in labels_dict.items() if value == el]\n",
    "        lista.append(l[0])\n",
    "    return lista\n",
    "\n",
    "\n",
    "def compare(test data, test_labels_one_hot, model):\n",
    "    lab_pred = model.predict(test_data)\n",
    "    pred_labels = np.argmax(lab_pred, axis=1)\n",
    "\n",
    "    test_labels = np.argmax(test_labels_one_hot, axis=1)\n",
    "\n",
    "    #asana_pred = int_to_asana(labels_pred)\n",
    "    #asana_test = int_to_asana(test_labels)\n",
    "    #df = pd.DataFrame({'pred': asana_pred, 'true': asana_test}, index=range(len(asana_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c2b49-c89b-40c8-b08d-de21c82051c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4f440-1769-4264-8b6d-d7cc9f915c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d556cce-13f3-4ce1-89f9-44ee2e6f24b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7ce14-0b27-4740-8343-e3a94c82936a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453cfb8a-6cc9-4019-824c-ed34a05e962b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73ef4d41-556d-4868-b077-56a76e7384f1",
   "metadata": {},
   "source": [
    "#### Ways to improve the model:\n",
    "- train set percentage\n",
    "- data augmentation parameters\n",
    "- num_layers and filters\n",
    "- opt function and learning rate\n",
    "- batch_size\n",
    "- num_epochs + add early_stopping\n",
    "- layer dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d037c91-4fe1-4567-b224-d4727092c56b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
