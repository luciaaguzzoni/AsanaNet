{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75bfbb27",
   "metadata": {},
   "source": [
    "#### Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e16cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Data Augmentation Libraries\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import precision_score\n",
    "#from sklearn.metrics import recall_score\n",
    "#from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "#from tensorflow.keras.datasets import mnist\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Conv2D\n",
    "#from tensorflow.keras.layers import MaxPool2D\n",
    "#from tensorflow.keras.layers import Flatten\n",
    "#from tensorflow.keras.layers import Dropout\n",
    "#from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import pickle\n",
    "\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a643638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48bdd2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0666d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6226a65",
   "metadata": {},
   "source": [
    "#### Workflow:\n",
    "- Crear entorno nuevo con versión python 3.11\n",
    "- instalar tensorflow\n",
    "- Data Augmentation\n",
    "- aplicar una CNN\n",
    "- reserch de los parámetros y de la estructura: feed forward? capas? dense layers? loss functions? auc? batch? epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3077322-4dba-4896-8cc3-b26b18c4886a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Data Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67389d3-985b-403d-a3bb-551e36afec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation, Noise, Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1418e11-3c1d-4bb0-a891-02fd68e727b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img):\n",
    "    '''Add random noise to an image'''\n",
    "    VARIABILITY = 50\n",
    "    deviation = VARIABILITY*random.random()\n",
    "    noise = np.random.normal(0, deviation, img.shape)\n",
    "    new_img = img + noise\n",
    "    np.clip(new_img, 0., 255.)\n",
    "    return new_img\n",
    "\n",
    "'''\n",
    "def change_contrast(img):      \n",
    "    for i in range(3):\n",
    "      seed = (i, 0)\n",
    "      contrast_image = tf.image.stateless_random_contrast(\n",
    "          img, lower=0.1, upper=0.9, seed=seed)\n",
    "      return contrast_image\n",
    "'''\n",
    "\n",
    "# Initialising the ImageDataGenerator class.\n",
    "# We will pass in the augmentation parameters in the constructor.\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range = 360,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True\n",
    "        preprocessing_function=add_noise,\n",
    "\n",
    "\n",
    "def augmentation(image_path, new_image_paths):\n",
    "    # Loading a sample image \n",
    "    img = load_img(image_path) \n",
    "    # Converting the input sample image to an array\n",
    "    x = img_to_array(img)\n",
    "    # Reshaping the input image\n",
    "    x = x.reshape((1, ) + x.shape)     \n",
    "\n",
    "    # Generating and saving 5 augmented samples \n",
    "    # using the above defined parameters. \n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size = 5,\n",
    "                              save_to_dir ='', \n",
    "                              save_prefix ='', save_format ='jpeg'): # mette automaticamente .1, .2 come suffisso\n",
    "        i+=1\n",
    "        if i==4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337cb1e4-e1c5-45a6-822d-35e1a895bb33",
   "metadata": {},
   "source": [
    "##### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f90989d9-f210-41d1-af73-8c9bc4e9a263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucia\\miniconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "# Add more layers as needed\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='softmax'))  # 100 output classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b7d08-87b8-439d-be65-5ca054c8eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator for data augmentation\n",
    "def add_noise(img):\n",
    "    #Add random noise to an image\n",
    "    VARIABILITY = 50\n",
    "    deviation = VARIABILITY*random.random()\n",
    "    noise = np.random.normal(0, deviation, img.shape)\n",
    "    new_img = img + noise\n",
    "    np.clip(new_img, 0., 255.)\n",
    "    return new_img\n",
    "    \n",
    "# Initialising the ImageDataGenerator class.\n",
    "# We will pass in the augmentation parameters in the constructor.\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range = 360,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True\n",
    "        preprocessing_function=add_noise\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset and split it into train, validation, and test sets\n",
    "\n",
    "# LOADING\n",
    "\n",
    "base_dir = '../data/dataset'\n",
    "all_image_paths = []\n",
    "all_labels = []\n",
    "\n",
    "# Walk through the directory structure\n",
    "for label in os.listdir(base_dir):\n",
    "    label_path = os.path.join(base_dir, label)\n",
    "\n",
    "    # Walk through the images in the subdirectory\n",
    "    for image_filename in os.listdir(label_path):\n",
    "        image_path = os.path.join(label_path, image_filename)\n",
    "\n",
    "        # Add the image path and corresponding label to the lists\n",
    "        all_image_paths.append(image_path)\n",
    "        all_labels.append(label)\n",
    "\n",
    "# Ensure that all_image_paths and all_labels are numpy arrays for easier manipulation\n",
    "image_paths = np.array(all_image_paths)\n",
    "labels = np.array(all_labels)\n",
    "\n",
    "\n",
    "# SPLITTING\n",
    "\n",
    "# Split the dataset into training and temporary sets (combined validation and test)\n",
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "    temp_paths, temp_labels, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e11441-f1a9-4555-b4a5-9cbe63708e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with data augmentation\n",
    "batch_size = 32 # number of training examples utilized in one iteration\n",
    "\n",
    "model.fit_generator(\n",
    "    datagen.flow(train_data, train_labels, batch_size=batch_size),\n",
    "    steps_per_epoch = len(train_data) / batch_size,  # adjust batch_size and steps_per_epoch accordingly\n",
    "    epochs=50,\n",
    "    validation_data=(val_data, val_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32e0cc2-8f2c-44df-8928-27c5fef7f5d7",
   "metadata": {},
   "source": [
    "\n",
    "In the line datagen.flow(train_data, train_labels, batch_size=batch_size), you are using the flow method of the ImageDataGenerator to create a generator that yields augmented batches of training data on-the-fly.\r\n",
    "\r\n",
    "Here's a breakdown of each parameter:\r\n",
    "\r\n",
    "train_data: This is the input training data, typically a numpy array or a directory path. In the context of ImageDataGenerator, it is expected to be a 4D array representing the images (samples) in the training dataset.\r\n",
    "\r\n",
    "train_labels: This is the corresponding labels for the training data. It could be one-hot encoded or categorical labels.\r\n",
    "\r\n",
    "batch_size: This parameter specifies the number of samples in each batch that the generator will yield.\r\n",
    "\r\n",
    "When you use datagen.flow(train_data, train_labels, batch_size=batch_size), the ImageDataGenerator takes care of applying the specified data augmentation techniques (e.g., rotation, width shift, height shift, horizontal flip, vertical flip, and your custom noise function add_noise) to the training data on-the-fly. It generates batches of augmented data during each iteration of training.\r\n",
    "\r\n",
    "Here's a simplified explanation of how the flow works:\r\n",
    "\r\n",
    "The generator takes a batch of batch_size samples from the training data.\r\n",
    "It applies the specified data augmentation techniques to each sample in the batch.\r\n",
    "It yields the augmented batch to the model for training.\r\n",
    "This process is repeated for each epoch during training. It allows you to artificially increase the size of your training dataset and introduce variability to improve the model's ability to generalize to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5ed73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a05035f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a690f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0741b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "(X_train,y_train) , (X_test,y_test)=mnist.load_data()\n",
    "\n",
    "#reshaping data\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],X_test.shape[2],1))\n",
    "\n",
    "#checking the shape after reshaping\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#normalizing the pixel values\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "\n",
    "#defining model\n",
    "model=Sequential()\n",
    "\n",
    "#adding convolution layer\n",
    "model.add(Conv2D(32,(3,3),activation=’relu’,input_shape=(28,28,1)))\n",
    "\n",
    "#adding pooling layer\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    "#adding fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation=’relu’))\n",
    "\n",
    "#adding output layer\n",
    "model.add(Dense(10,activation=’softmax’))\n",
    "\n",
    "#compiling the model\n",
    "model.compile(loss=’sparse_categorical_crossentropy’,optimizer=’adam’,metrics=[‘accuracy’])\n",
    "\n",
    "#fitting the model\n",
    "model.fit(X_train,y_train,epochs=10)\n",
    "\n",
    "#evaluting the model\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dedee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ec3c044",
   "metadata": {},
   "source": [
    "#### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3804b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    # Function to load and preprocess images from a folder\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            img = cv2.resize(img, (64, 64))  # Resize image ###########################\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folders_in_directory(directory_path):\n",
    "    # Get the list of all files and folders in the specified directory\n",
    "    items = os.listdir(directory_path)\n",
    "\n",
    "    # Filter out only the folders from the list\n",
    "    folders = [item for item in items if os.path.isdir(os.path.join(directory_path, item))]\n",
    "\n",
    "    return folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e9846d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ebe73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19065a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88a3a599",
   "metadata": {},
   "source": [
    "#### 'main':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60154947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path of the directory you want to list folders from\n",
    "directory_path = '../data/dataset'\n",
    "\n",
    "# Call the function to get the list of folders\n",
    "asana = get_folders_in_directory(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7d231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63aaa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and give labels\n",
    "X=[]\n",
    "y=[]\n",
    "for asana_name in asana:\n",
    "    path = directory_path + asana_name\n",
    "    X = X + load_images_from_folder(asana_name)\n",
    "    y.append(asana_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce26d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the image data\n",
    "X = X.reshape(X.shape[0], -1) # ??????????????????\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40) \n",
    "'''\n",
    "random_state : int, default=None. Controls the shuffling applied to the data before applying the split.\n",
    "                Pass an int for reproducible output across multiple function calls.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc58c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the following for different models and compare\n",
    "\n",
    "\n",
    "# Train logistic regression model\n",
    "'''\n",
    "ex:\n",
    "model = ()\n",
    "model.fit(X_train, y_train)\n",
    "'''\n",
    "\n",
    "# Evaluate model on test set\n",
    "'''\n",
    "ex:\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"F1 score: {f1_score(y_test, y_pred)}\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa466cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7cf0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model\n",
    "\n",
    "'''\n",
    "model_file = '../models/asana_model.pkl'\n",
    "with open(model_file, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405676b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b94ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "model_file = '../models/logistic_cats_dogs.pkl' # pickle (pkl), .h5, ...\n",
    "with open(model_file, 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f6322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d3a36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
